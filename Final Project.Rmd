---
title: "Data Collection"
author: "Everett Brown"
date: "5/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:\\Users\\Everett\\CMSC320Final");
library(lubridate)
library(tidyverse)
library(dplyr)
library(gtrendsR)
library(rvest)
```




Getting coronavirus states data form https://github.com/nytimes/covid-19-data
```{r}
#if you want to update data, uncomment the following line
#download.file("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv","states_data.csv")
corona_state_data <- read_csv(paste(getwd(), "/states_data.csv", sep = ""))
```

Reading State abbreviations into dataframe- for later use
```{r}
state_codes <- read_csv(paste(getwd(), "/state_codes.csv", sep = "")) %>%
    select(State, Code) %>%
    mutate(Code = paste("US-",Code,sep=""))
```

Reformatting
```{r}
corona_state_data <- corona_state_data %>%
    mutate(date = ymd(date)) %>%
    select(state, date, cases, deaths) %>%
    filter(state %in% state_codes$State)
```






Downloading state lockdown data from wikipedia
```{r}
url <- "https://en.wikipedia.org/wiki/U.S._state_and_local_government_response_to_the_COVID-19_pandemic"

lockdown_data <-  url %>% read_html() %>%
    html_node(".wikitable") %>%
    html_table(fill = TRUE) 

```

Reformatting lockdown data
```{r}
lockdown_data <- lockdown_data %>%
    setNames(make.names(names(.), unique = TRUE)) %>% 
    select( 1,4) %>%
    slice(2:n())

names(lockdown_data) <- c("state", "lockdown_start")

lockdown_data <- lockdown_data %>%
    mutate(lockdown_start = ymd(paste("2020",lockdown_start))) %>%
    filter(state %in% state_codes$State)
```


Adding lockdown data to state dataframe
```{r}
corona_state_data <- corona_state_data %>%
    left_join(lockdown_data, by = "state") %>%
    mutate(in_lockdown = ifelse(is.na(lockdown_start), F, ifelse(date >= lockdown_start, T,F)))
```


Creating a function that pulls google trend data and adds it to the lockdown_data dataframe
```{r}


add_term <- function(term){
  all_trends <- gtrends(keyword = term, geo = state_codes$Code[1], time = "today 3-m", onlyInterest = T)[[1]]
    all_trends <- all_trends %>%
       select(date, hits) %>%
       mutate(state = state_codes$State[1]) %>%
       mutate(date = ymd(date))
  
  names(all_trends)[2] = paste(term,"_hits", sep = "")
  
  for(i in 1:50){
    trend_df <- gtrends(keyword = term, geo = state_codes$Code[i], time = "today 3-m", onlyInterest = T)[[1]]
    
    trend_df <- trend_df %>%
       select(date, hits) %>%
       mutate(state = state_codes$State[i]) %>%
       mutate(date = ymd(date))

    names(trend_df)[2] = paste(term,"_hits", sep = "")
  
    all_trends <- rbind(trend_df, all_trends)
  }
  
  
  df <-  corona_state_data %>% left_join(all_trends, by = c("state","date"))
  return(df)
}
```
Note: only data from last 90 days is included


Adding terms to track
Note: pulling the data from google takes a while, expect 20-30 seconds per term
Also: sometimes it just fails, the gtrends() doesn't always work.
It is best to run this line by line, by highlighting a line and hitting ctrl enter
we will have to come up for a workaround for this before knitting
Or maybe my internet is just bad lol, idk

And sometimes it works copmletely fine too, idk whats up

It seems like waiting a minute before calling each line somehow helps as well, so there's that

NEW UPDATE: it seems as though uninstalling and reinstalling 
```{r}
corona_state_data <- add_term("coronavirus")
corona_state_data <- add_term("toilet paper")
corona_state_data <- add_term("ticketmaster")
corona_state_data <- add_term("bread")
corona_state_data <- add_term("lockdown")
corona_state_data <- add_term("run")
corona_state_data <- add_term("cook")
#add things that could be interesting!

```



Exploratory data analysis:

Example of comparing search rates for something before and after lockdown
Note: data is skewed because some states never went into lockdown, but the scale is still from 1-100
```{r}

corona_state_data %>% 
    filter(!is.na(run_hits)) %>%
    ggplot(mapping=aes(x=in_lockdown, y=run_hits)) +
    geom_boxplot()


```


Heres another one
```{r}

corona_state_data %>% 
    filter(!is.na(ticketmaster_hits)) %>%
    ggplot(mapping=aes(x=in_lockdown, y=ticketmaster_hits)) +
    geom_violin()


```




Number of corona cases before lockdown
```{r}
corona_state_data %>%
  mutate(log_cases = log2(cases)) %>%
  group_by(state) %>%
  ggplot(aes(x = date, y = log_cases,color = in_lockdown)) + 
  geom_point()
```


Adding normalized corona data- google trend data is on a scale from 0-100, so 
here we're putting the cases on a scale from 0 to 100 percent
This allows for cases and search terms to be graphed together
```{r}
corona_state_data <- corona_state_data %>%
  group_by(state) %>%
  mutate(max_cases = max(cases)) %>%
  mutate(max_deaths = max(deaths)) %>%
  ungroup() %>%
  mutate(percent_cases = 100*cases/max_cases) %>%
  mutate(percent_deaths = 100*deaths/max_deaths) 
  
```



For example, here is a comparison of searches for "coronavirus", and the number of cases of coronavirus in NY


```{r}
corona_state_data %>%
    filter(state == "New York") %>%
    ggplot(aes(x = date)) + 
    geom_line(aes(y = percent_cases, col = "Percent of max cases")) + 
    geom_line(aes(y = coronavirus_hits, col = "Searches for coronavirus"))
```
















